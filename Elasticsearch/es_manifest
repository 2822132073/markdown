``yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  generation: 25
  labels:
    app: test-master
    chart: elasticsearch
    heritage: Tiller
    release: test-master
  name: test-master
  namespace: test
spec:
  podManagementPolicy: Parallel
  replicas: 3
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: test-master
  serviceName: test-master-headless
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: test-master
        chart: elasticsearch
        heritage: Tiller
        release: test-master
      name: test-master
    spec:
      containers:
      - env:
        - name: node.name
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: cluster.initial_master_nodes
          value: test-master-0,test-master-1,test-master-2
        - name: discovery.seed_hosts
          value: test-master-headless
        - name: cluster.name
          value: similar-local-7-14
        - name: network.host
          value: 0.0.0.0
        - name: ES_JAVA_OPTS
          value: -Xmx1g -Xms1g
        - name: node.data
          value: "false"
        - name: node.ingest
          value: "false"
        - name: node.master
          value: "true"
        image: harbor.laibokeji.com/elasticsearch/elasticsearch-ik-not-add:7.14.0
        imagePullPolicy: IfNotPresent
        name: elasticsearch
        ports:
        - containerPort: 9200
          name: http
          protocol: TCP
        - containerPort: 9300
          name: transport
          protocol: TCP
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - |
              #!/usr/bin/env bash -e
              # If the node is starting up wait for the cluster to be ready (request params: 'wait_for_status=green&timeout=1s' )
              # Once it has started only check that the node itself is responding
              START_FILE=/tmp/.es_start_file

              if [ -n "${ELASTIC_USERNAME}" ] && [ -n "${ELASTIC_PASSWORD}" ]; then
                BASIC_AUTH="-u ${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"
              else
                BASIC_AUTH=''
              fi

              if [ -f "${START_FILE}" ]; then
                echo 'Elasticsearch is already running, lets check the node is healthy'
                HTTP_CODE=$(curl -XGET -s -k ${BASIC_AUTH} -o /dev/null -w '%{http_code}' http://127.0.0.1:9200/)
                RC=$?
                if [[ ${RC} -ne 0 ]]; then
                  echo "curl -XGET -s -k \${BASIC_AUTH} -o /dev/null -w '%{http_code}' http://127.0.0.1:9200/ failed with RC ${RC}"
                  exit ${RC}
                fi
                # ready if HTTP code 200, 503 is tolerable if ES version is 6.x
                if [[ ${HTTP_CODE} == "200" ]]; then
                  exit 0
                elif [[ ${HTTP_CODE} == "503" && "7" == "6" ]]; then
                  exit 0
                else
                  echo "curl -XGET -s -k \${BASIC_AUTH} -o /dev/null -w '%{http_code}' http://127.0.0.1:9200/ failed with HTTP code ${HTTP_CODE}"
                  exit 1
                fi

              else
                echo 'Waiting for elasticsearch cluster to become ready (request params: "wait_for_status=green&timeout=1s" )'
                if curl -XGET -s -k --fail ${BASIC_AUTH} http://127.0.0.1:9200/_cluster/health?wait_for_status=green&timeout=1s ; then
                  touch ${START_FILE}
                  exit 0
                else
                  echo 'Cluster is not yet ready (request params: "wait_for_status=green&timeout=1s" )'
                  exit 1
                fi
              fi
          failureThreshold: 3
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 3
          timeoutSeconds: 5
        resources:
          limits:
            cpu: "1"
            memory: 1Gi
          requests:
            cpu: "1"
            memory: 1Gi
        securityContext:
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          runAsUser: 1000
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /usr/share/elasticsearch/data
          name: test-master
        - mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
          name: esconfig
          subPath: elasticsearch.yml
      dnsPolicy: ClusterFirst
      initContainers:
      - command:
        - sysctl
        - -w
        - vm.max_map_count=262144
        image: harbor.laibokeji.com/elasticsearch/elasticsearch-ik-not-add:7.14.0
        imagePullPolicy: IfNotPresent
        name: configure-sysctl
        resources: {}
        securityContext:
          privileged: true
          runAsUser: 0
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      terminationGracePeriodSeconds: 120
      volumes:
      - configMap:
          defaultMode: 420
          name: test-master-config
        name: esconfig
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      name: test-master
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 12Gi
      storageClassName: ceph-nvme-rbd-new
      volumeMode: Filesystem
```






```yaml
apiVersion: v1
items:
- apiVersion: v1
  data:
    elasticsearch.yml: |-
      indices.memory.index_buffer_size: 30%
      http.cors.enabled: true
      http.cors.allow-origin: "*"
  kind: ConfigMap
  metadata:
    creationTimestamp: "2021-04-04T13:38:01Z"
    labels:
      cattle.io/creator: norman
    name: test-master-config
    namespace: test
kind: List

```

















```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: test-ingest
    chart: elasticsearch
    heritage: Tiller
    release: test-ingest
  name: test-ingest
  namespace: test
spec:
  podManagementPolicy: Parallel
  replicas: 2
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: test-ingest
  serviceName: test-ingest-headless
  template:
    metadata:
      labels:
        app: test-ingest
        chart: elasticsearch
        heritage: Tiller
        release: test-ingest
      name: test-ingest
    spec:
      containers:
      - env:
        - name: node.name
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: cluster.initial_master_nodes
          value: test-master-0,test-master-1,test-master-2
        - name: discovery.seed_hosts
          value: test-master-headless
        - name: cluster.name
          value: similar-local-7-14
        - name: network.host
          value: 0.0.0.0
        - name: ES_JAVA_OPTS
          value: -Xmx1g -Xms1g
        - name: node.data
          value: "false"
        - name: node.ingest
          value: "true"
        - name: node.master
          value: "false"
        image: harbor.laibokeji.com/elasticsearch/elasticsearch-ik-not-add:7.14.0
        imagePullPolicy: IfNotPresent
        name: elasticsearch
        ports:
        - containerPort: 9200
          name: http
          protocol: TCP
        - containerPort: 9300
          name: transport
          protocol: TCP
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - |
              #!/usr/bin/env bash -e
              # If the node is starting up wait for the cluster to be ready (request params: 'wait_for_status=green&timeout=1s' )
              # Once it has started only check that the node itself is responding
              START_FILE=/tmp/.es_start_file

              if [ -n "${ELASTIC_USERNAME}" ] && [ -n "${ELASTIC_PASSWORD}" ]; then
                BASIC_AUTH="-u ${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"
              else
                BASIC_AUTH=''
              fi

              if [ -f "${START_FILE}" ]; then
                echo 'Elasticsearch is already running, lets check the node is healthy'
                HTTP_CODE=$(curl -XGET -s -k ${BASIC_AUTH} -o /dev/null -w '%{http_code}' http://127.0.0.1:9200/)
                RC=$?
                if [[ ${RC} -ne 0 ]]; then
                  echo "curl -XGET -s -k \${BASIC_AUTH} -o /dev/null -w '%{http_code}' http://127.0.0.1:9200/ failed with RC ${RC}"
                  exit ${RC}
                fi
                # ready if HTTP code 200, 503 is tolerable if ES version is 6.x
                if [[ ${HTTP_CODE} == "200" ]]; then
                  exit 0
                elif [[ ${HTTP_CODE} == "503" && "7" == "6" ]]; then
                  exit 0
                else
                  echo "curl -XGET -s -k \${BASIC_AUTH} -o /dev/null -w '%{http_code}' http://127.0.0.1:9200/ failed with HTTP code ${HTTP_CODE}"
                  exit 1
                fi

              else
                echo 'Waiting for elasticsearch cluster to become ready (request params: "wait_for_status=green&timeout=1s" )'
                if curl -XGET -s -k --fail ${BASIC_AUTH} http://127.0.0.1:9200/_cluster/health?wait_for_status=green&timeout=1s ; then
                  touch ${START_FILE}
                  exit 0
                else
                  echo 'Cluster is not yet ready (request params: "wait_for_status=green&timeout=1s" )'
                  exit 1
                fi
              fi
          failureThreshold: 3
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 3
          timeoutSeconds: 5
        resources:
          limits:
            cpu: "1"
            memory: 1Gi
          requests:
            cpu: "1"
            memory: 1Gi
        securityContext:
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          runAsUser: 1000
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /usr/share/elasticsearch/data
          name: test-ingest
        - mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
          name: esconfig
          subPath: elasticsearch.yml
      dnsPolicy: ClusterFirst
      initContainers:
      - command:
        - sysctl
        - -w
        - vm.max_map_count=262144
        image: harbor.laibokeji.com/busybox/busybox:latest
        imagePullPolicy: IfNotPresent
        name: configure-sysctl
        resources: {}
        securityContext:
          privileged: true
          runAsUser: 0
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      terminationGracePeriodSeconds: 120
      volumes:
      - configMap:
          defaultMode: 420
          name: test-master-config
        name: esconfig
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      name: test-ingest
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 12Gi
      storageClassName: ceph-nvme-rbd-new
      volumeMode: Filesystem
```

















```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  generation: 87
  labels:
    app: test-data
  name: test-data
  namespace: test
spec:
  podManagementPolicy: Parallel
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: test-data
  serviceName: test-data
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: test-data
      containers:
      - env:
        - name: ES_JAVA_OPTS
          value: -Xmx1g -Xms1g
        - name: cluster.initial_master_nodes
          value: test-master-0,test-master-1,test-master-2
        - name: cluster.name
          value: similar-local-7-14
        - name: discovery.seed_hosts
          value: test-master-headless
        - name: network.host
          value: 0.0.0.0
        - name: node.data
          value: "true"
        - name: node.ingest
          value: "false"
        - name: node.master
          value: "false"
        - name: node.name
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.nodeName
        image: harbor.laibokeji.com/elasticsearch/elasticsearch-ik:7.14.0
        imagePullPolicy: IfNotPresent
        name: elasticsearch
        ports:
        - containerPort: 9200
          name: http
          protocol: TCP
        - containerPort: 9300
          name: transport
          protocol: TCP
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - |2




              START_FILE=/tmp/.es_start_file



              if [ -n "${ELASTIC_USERNAME}" ] && [ -n "${ELASTIC_PASSWORD}" ]; then

                BASIC_AUTH="-u ${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"

              else

                BASIC_AUTH=''

              fi



              if [ -f "${START_FILE}" ]; then

                echo 'Elasticsearch is already running, lets check the node is healthy'

                HTTP_CODE=$(curl -XGET -s -k ${BASIC_AUTH} -o /dev/null -w '%{http_code}' http://127.0.0.1:9200/)

                RC=$?

                if [[ ${RC} -ne 0 ]]; then

                  echo "curl -XGET -s -k \${BASIC_AUTH} -o /dev/null -w '%{http_code}' http://127.0.0.1:9200/ failed with RC ${RC}"

                  exit ${RC}

                fi


                if [[ ${HTTP_CODE} == "200" ]]; then

                  exit 0

                elif [[ ${HTTP_CODE} == "503" && "7" == "6" ]]; then

                  exit 0

                else

                  echo "curl -XGET -s -k \${BASIC_AUTH} -o /dev/null -w '%{http_code}' http://127.0.0.1:9200/ failed with HTTP code ${HTTP_CODE}"

                  exit 1

                fi



              else

                echo 'Waiting for elasticsearch cluster to become ready (request params: "wait_for_status=green&timeout=1s" )'

                if curl -XGET -s -k --fail ${BASIC_AUTH} http://127.0.0.1:9200/_cluster/health?wait_for_status=green&timeout=1s ; then

                  touch ${START_FILE}

                  exit 0

                else

                  echo 'Cluster is not yet ready (request params: "wait_for_status=green&timeout=1s" )'

                  exit 1

                fi

              fi
          failureThreshold: 3
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 3
          timeoutSeconds: 5
        resources:
          limits:
            cpu: "1"
            memory: 1Gi
          requests:
            cpu: "1"
            memory: 1Gi
        securityContext:
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          runAsUser: 1000
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /usr/share/elasticsearch/data
          name: elasticsearch-data
        - mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
          name: esconfig
          subPath: elasticsearch.yml
      dnsPolicy: ClusterFirst
      initContainers:
      - command:
        - sysctl
        - -w
        - vm.max_map_count=262144
        image: harbor.laibokeji.com/elasticsearch/elasticsearch-ik-not-add:7.14.0
        imagePullPolicy: IfNotPresent
        name: configure-sysctl
        resources: {}
        securityContext:
          privileged: true
          runAsUser: 0
        terminationMessagePath: /dev/termination-log
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      terminationGracePeriodSeconds: 1800
      volumes:
      - configMap:
          defaultMode: 420
          name: test-master-config
        name: esconfig
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        name: elasticsearch-data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 12Gi
        storageClassName: ceph-nvme-rbd-new
        volumeMode: Filesystem
```


```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "4"
    field.cattle.io/publicEndpoints: '[{"addresses":["192.168.7.11"],"port":80,"protocol":"HTTP","serviceName":"test:kibana-test","ingressName":"test:kibana-test","hostname":"kibana-test.k8s.laibokeji.com","allNodes":true}]'
  creationTimestamp: "2021-04-04T13:38:01Z"
  generation: 9
  labels:
    app: kibana
    release: kibana-test
  name: kibana-test
  namespace: test
  resourceVersion: "1215561903"
  selfLink: /apis/apps/v1/namespaces/test/deployments/kibana-test
  uid: 13a0747a-6385-423f-920f-1a3a5fddfbbf
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: kibana
      release: kibana-test
  strategy:
    type: Recreate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: kibana
        release: kibana-test
    spec:
      containers:
      - env:
        - name: ELASTICSEARCH_HOSTS
          value: http://test-master:9200
        - name: SERVER_HOST
          value: 0.0.0.0
        - name: NODE_OPTIONS
          value: --max-old-space-size=1800
        image: harbor.laibokeji.com/elasticsearch/kibana:7.14.0
        imagePullPolicy: IfNotPresent
        name: kibana
        ports:
        - containerPort: 5601
          protocol: TCP
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - |
              #!/usr/bin/env bash -e
              http () {
                  local path="${1}"
                  set -- -XGET -s --fail -L

                  if [ -n "${ELASTICSEARCH_USERNAME}" ] && [ -n "${ELASTICSEARCH_PASSWORD}" ]; then
                    set -- "$@" -u "${ELASTICSEARCH_USERNAME}:${ELASTICSEARCH_PASSWORD}"
                  fi

                  STATUS=$(curl --output /dev/null --write-out "%{http_code}" -k "$@" "http://localhost:5601${path}")
                  if [[ "${STATUS}" -eq 200 ]]; then
                    exit 0
                  fi

                  echo "Error: Got HTTP code ${STATUS} but expected a 200"
                  exit 1
              }

              http "/app/kibana"
          failureThreshold: 3
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 3
          timeoutSeconds: 5
        resources:
          limits:
            cpu: "2"
            memory: 8Gi
          requests:
            cpu: 10m
            memory: 2Gi
        securityContext:
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          runAsUser: 1000
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        fsGroup: 1000
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 1
  conditions:
  - lastTransitionTime: "2021-08-24T06:16:48Z"
    lastUpdateTime: "2021-08-24T06:26:27Z"
    message: ReplicaSet "kibana-test-85f7df8657" has successfully progressed.
    reason: NewReplicaSetAvailable
    status: "True"
    type: Progressing
  - lastTransitionTime: "2021-08-30T09:15:37Z"
    lastUpdateTime: "2021-08-30T09:15:37Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: "True"
    type: Available
  observedGeneration: 9
  readyReplicas: 1
  replicas: 1
  updatedReplicas: 1
```

```yaml
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2021-04-04T13:38:01Z"
    labels:
      app: kibana
      release: kibana-test
    name: kibana-test
    namespace: test
    resourceVersion: "761261227"
    selfLink: /api/v1/namespaces/test/services/kibana-test
    uid: 44f281cb-aec1-4ae5-8629-4b7df659a1ce
  spec:
    clusterIP: 10.43.183.8
    ports:
    - name: http
      port: 5601
      protocol: TCP
      targetPort: 5601
    selector:
      app: kibana
      release: kibana-test
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2021-04-04T13:38:01Z"
    labels:
      app: test-data
    name: test-data
    namespace: test
    resourceVersion: "761261228"
    selfLink: /api/v1/namespaces/test/services/test-data
    uid: 38123af4-cd4e-4e73-ae37-6c3d5f837c88
  spec:
    clusterIP: None
    ports:
    - name: http
      port: 9200
      protocol: TCP
      targetPort: 9200
    - name: transport
      port: 9300
      protocol: TCP
      targetPort: 9300
    selector:
      app: test-data
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      field.cattle.io/publicEndpoints: '[{"addresses":["192.168.6.142"],"port":31973,"protocol":"TCP","serviceName":"test:test-ingest","allNodes":true},{"addresses":["192.168.6.142"],"port":30177,"protocol":"TCP","serviceName":"test:test-ingest","allNodes":true}]'
    creationTimestamp: "2021-04-04T13:38:01Z"
    labels:
      app: test-ingest
    name: test-ingest
    namespace: test
    resourceVersion: "1130875297"
    selfLink: /api/v1/namespaces/test/services/test-ingest
    uid: 6a20ed6d-4686-45f1-8d87-9b3fddf36367
  spec:
    clusterIP: 10.43.188.15
    externalTrafficPolicy: Cluster
    ports:
    - name: http
      nodePort: 31973
      port: 9200
      protocol: TCP
      targetPort: 9200
    - name: transport
      nodePort: 30177
      port: 9300
      protocol: TCP
      targetPort: 9300
    selector:
      app: test-ingest
    sessionAffinity: None
    type: NodePort
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2021-04-04T13:38:01Z"
    labels:
      app: test-ingest
    name: test-ingest-headless
    namespace: test
    resourceVersion: "761261237"
    selfLink: /api/v1/namespaces/test/services/test-ingest-headless
    uid: f4f81ee7-7062-4041-9e89-ff6187dc4a90
  spec:
    clusterIP: None
    ports:
    - name: http
      port: 9200
      protocol: TCP
      targetPort: 9200
    - name: transport
      port: 9300
      protocol: TCP
      targetPort: 9300
    selector:
      app: test-ingest
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      field.cattle.io/publicEndpoints: '[{"addresses":["192.168.6.142"],"port":32408,"protocol":"TCP","serviceName":"test:test-master","allNodes":true},{"addresses":["192.168.6.142"],"port":31759,"protocol":"TCP","serviceName":"test:test-master","allNodes":true}]'
    creationTimestamp: "2021-04-04T13:38:01Z"
    labels:
      app: test-master
    name: test-master
    namespace: test
    resourceVersion: "1130875266"
    selfLink: /api/v1/namespaces/test/services/test-master
    uid: 57c7e562-2763-45d0-a5be-4761b06e2a8b
  spec:
    clusterIP: 10.43.236.210
    externalTrafficPolicy: Cluster
    ports:
    - name: http
      nodePort: 32408
      port: 9200
      protocol: TCP
      targetPort: 9200
    - name: transport
      nodePort: 31759
      port: 9300
      protocol: TCP
      targetPort: 9300
    selector:
      app: test-master
    sessionAffinity: None
    type: NodePort
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2021-04-04T13:38:01Z"
    labels:
      app: test-master
    name: test-master-headless
    namespace: test
    resourceVersion: "761261246"
    selfLink: /api/v1/namespaces/test/services/test-master-headless
    uid: 4f40a97c-361c-49cb-9738-a97f40e73975
  spec:
    clusterIP: None
    ports:
    - name: http
      port: 9200
      protocol: TCP
      targetPort: 9200
    - name: transport
      port: 9300
      protocol: TCP
      targetPort: 9300
    selector:
      app: test-master
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
```
